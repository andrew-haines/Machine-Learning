neural network data preprocessing

- calculate average baseline from 4EG_1_0ppb, 4EG_2_0ppb, 4EP_1_0ppb, 4EP_2_0ppb.

- using ksmoothing to average points over a kernel window

- smooth datapoints so it doesnt sample every 0.5 seconds. observe graph to determine
  interval to smooth over. 
  
- observe which sensors react to 4EG and 4EP presence respectively.
	- both react to T70/2, T30/1, PA2 only really. 
	- 4EG starts with a negative impact on these sensors, rises, and then decreases
	- 4EP starts by a positive impact on these sensors and then naturally decays.
  
- determine if any sensors simply dont react to the presence of these analytes in callibration set

- Remove these features if this is the case

- subtract smoothed baseline from all smoothed training sets and callibration sets.

- The result will be input to the NN

neural network process

## k means. Determining prototypes
- chose k

- run batch k means algorithm to determine the prototypes

- remove prototypes that have no data points associated with them

- calculate sigma covariance matrix using data points associated with each prototype. 
  Only useful if we have lots of datapoints. 
  Try, fail, then pick sigma using n fold cross validation 
  
- once we have k prototypes, compute distance matrix between N data points (feature set) and prototypes (n x k)

- Add bias 

- calculate weights based on distance matrix calculated above and the expected results (D) of 
  the provided N data points (so |expected results| = N) using pseudoinverse. W = pinv(distanceMatrix) . D

- perform whitening on input to remove correlation between features resulting in new feature space

- check if any of the new features can be pruned

- send resultant feature space to RBF for training

- check performance using K fold cross validation of training set to test set

- once confident in the model, process the prediction set to get 4EG, 4EP quantities

