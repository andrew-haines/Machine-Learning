
5 fold cross validation

"Considering k= 5 desamplingsize= 20 lambda 0"
[1] "average error is: 789836.76287517"
[1] "max error is: 2686578.60322984"
[1] "min error is: 150242.036166698"
[1] "error rate calculated as 789836.76287517"
[1] "Considering k= 5 desamplingsize= 20 lambda 0.5"

[1] "average error is: 664049.3793104"
[1] "max error is: 2854634.95662877"
[1] "min error is: 67297.9410281439"
[1] "error rate calculated as 664049.3793104"
[1] "Considering k= 5 desamplingsize= 20 lambda 1"
[1] "preprocessed dataset from 15613 dimensions into  93 new dimensions"

[1] "average error is: 357322.629613509"
[1] "max error is: 481094.496966938"
[1] "min error is: 187131.488170683"
[1] "error rate calculated as 357322.629613509"
[1] "Considering k= 5 desamplingsize= 20 lambda 2"
[1] "preprocessed dataset from 15613 dimensions into  93 new dimensions"

[1] "finished preprocessing 38 instances. Training network"
[1] "average error is: 709482.117840974"
[1] "max error is: 2725251.25303301"
[1] "min error is: 91356.6565542867"
[1] "error rate calculated as 709482.117840974"
[1] "Considering k= 5 desamplingsize= 20 lambda 4"
[1] "preprocessed dataset from 15613 dimensions into  93 new dimensions"
[1] "average error is: 738082.032496348"
[1] "max error is: 2968951.09391699"
[1] "min error is: 62516.5023128434"
[1] "error rate calculated as 738082.032496348"
[1] "Considering k= 5 desamplingsize= 20 lambda 8"
[1] "preprocessed dataset from 15613 dimensions into  93 new dimensions"
[1] "average error is: 766766.327158803"
[1] "max error is: 2751630.53586134"
[1] "min error is: 82453.1242305795"
[1] "error rate calculated as 766766.327158803"
[1] "Considering k= 5 desamplingsize= 20 lambda 16"
[1] "preprocessed dataset from 15613 dimensions into  93 new dimensions"
[1] "average error is: 763189.565144828"
[1] "max error is: 3006288.21560133"
[1] "min error is: 14077.3816752827"
[1] "error rate calculated as 763189.565144828"
[1] "Considering k= 5 desamplingsize= 20 lambda 32"
[1] "preprocessed dataset from 15613 dimensions into  93 new dimensions"
[1] "average error is: 708744.399160274"
[1] "max error is: 2872673.67593734"
[1] "min error is: 89999.9669227844"
[1] "error rate calculated as 708744.399160274"
[1] "Considering k= 5 desamplingsize= 20 lambda 64"
[1] "average error is: 799311.34808788"
[1] "max error is: 3057625.69266865"
[1] "min error is: 16192.442564323"
[1] "error rate calculated as 799311.34808788"
[1] "Considering k= 5 desamplingsize= 20 lambda 128"
[1] "preprocessed dataset from 15613 dimensions into  93 new dimensions"
[1] "average error is: 762484.772470473"
[1] "max error is: 3333704.85261233"
[1] "min error is: 7627.40690284411"
[1] "error rate calculated as 762484.772470473"
[1] "Considering k= 5 desamplingsize= 30 lambda 0"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "average error is: 194956.356976913"
[1] "max error is: 343239.125855741"
[1] "min error is: 38651.6108521982"
[1] "error rate calculated as 194956.356976913"
[1] "Considering k= 5 desamplingsize= 30 lambda 0.5"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "average error is: 723948.185333408"
[1] "max error is: 2913918.04001427"
[1] "min error is: 113393.552215232"
[1] "error rate calculated as 723948.185333408"
[1] "Considering k= 5 desamplingsize= 30 lambda 1"
[1] "average error is: 761139.153235758"
[1] "max error is: 2783718.39635047"
[1] "min error is: 192028.655172436"
[1] "error rate calculated as 761139.153235758"
[1] "Considering k= 5 desamplingsize= 30 lambda 2"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "average error is: 737015.779872832"
[1] "max error is: 2907121.74977189"
[1] "min error is: 46671.7436427939"
[1] "error rate calculated as 737015.779872832"
[1] "Considering k= 5 desamplingsize= 30 lambda 4"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "finished preprocessing 38 instances. Training network"
[1] "average error is: 742176.463113288"
[1] "max error is: 2784223.95096874"
[1] "min error is: 58501.9555336479"
[1] "error rate calculated as 742176.463113288"
[1] "Considering k= 5 desamplingsize= 30 lambda 8"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "average error is: 757788.914257711"
[1] "max error is: 2989296.78787606"
[1] "min error is: 46972.0520010677"
[1] "error rate calculated as 757788.914257711"
[1] "Considering k= 5 desamplingsize= 30 lambda 16"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "average error is: 798587.776303292"
[1] "max error is: 3200920.24218086"
[1] "min error is: 15572.0138414527"
[1] "error rate calculated as 798587.776303292"
[1] "Considering k= 5 desamplingsize= 30 lambda 32"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "average error is: 817573.45507179"
[1] "max error is: 2931041.43525511"
[1] "min error is: 138308.20911815"
[1] "error rate calculated as 817573.45507179"
[1] "Considering k= 5 desamplingsize= 30 lambda 64"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "average error is: 788104.171063945"
[1] "max error is: 3021794.54893007"
[1] "min error is: 12638.1680164159"
[1] "error rate calculated as 788104.171063945"
[1] "Considering k= 5 desamplingsize= 30 lambda 128"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "average error is: 1416943.58838715"
[1] "max error is: 3475620.89663635"
[1] "min error is: 73733.1267355221"
[1] "error rate calculated as 1416943.58838715"
[1] "Considering k= 5 desamplingsize= 40 lambda 0"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "average error is: 752672.842650362"
[1] "max error is: 3005279.00542992"
[1] "min error is: 135995.24849934"
[1] "error rate calculated as 752672.842650362"
[1] "Considering k= 5 desamplingsize= 40 lambda 0.5"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "average error is: 681329.54099139"
[1] "max error is: 2622106.62164954"
[1] "min error is: 96079.3657083569"
[1] "error rate calculated as 681329.54099139"
[1] "Considering k= 5 desamplingsize= 40 lambda 1"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "average error is: 721168.806236016"
[1] "max error is: 2754071.31265971"
[1] "min error is: 144646.385216354"
[1] "error rate calculated as 721168.806236016"
[1] "Considering k= 5 desamplingsize= 40 lambda 2"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "average error is: 199000.245449646"
[1] "max error is: 499370.439803842"
[1] "min error is: 31283.4907998467"
[1] "error rate calculated as 199000.245449646"
[1] "Considering k= 5 desamplingsize= 40 lambda 4"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  93 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  93 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  93 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  93 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  93 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  93 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  93 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  93 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  93 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  93 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  93 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  93 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  93 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  93 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  93 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  93 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  93 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  93 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  93 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  93 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  93 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  93 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  93 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  93 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  93 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  93 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  93 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  93 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  93 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  93 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  93 new dimensions"
[1] "finished preprocessing 38 instances. Training network"
[1] "average error is: 799311.34808788"
[1] "max error is: 3057625.69266865"
[1] "min error is: 16192.442564323"
[1] "error rate calculated as 799311.34808788"
[1] "Considering k= 5 desamplingsize= 20 lambda 128"
[1] "preprocessed dataset from 15613 dimensions into  93 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  93 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  93 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  93 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  93 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  93 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  93 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  93 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  93 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  93 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  93 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  93 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  93 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  93 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  93 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  93 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  93 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  93 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  93 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  93 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  93 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  93 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  93 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  93 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  93 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  93 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  93 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  93 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  93 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  93 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  93 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  93 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  93 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  93 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  93 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  93 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  93 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  93 new dimensions"
[1] "finished preprocessing 38 instances. Training network"
[1] "average error is: 762484.772470473"
[1] "max error is: 3333704.85261233"
[1] "min error is: 7627.40690284411"
[1] "error rate calculated as 762484.772470473"
[1] "Considering k= 5 desamplingsize= 30 lambda 0"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "finished preprocessing 38 instances. Training network"
[1] "average error is: 194956.356976913"
[1] "max error is: 343239.125855741"
[1] "min error is: 38651.6108521982"
[1] "error rate calculated as 194956.356976913"
[1] "Considering k= 5 desamplingsize= 30 lambda 0.5"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "finished preprocessing 38 instances. Training network"
[1] "average error is: 723948.185333408"
[1] "max error is: 2913918.04001427"
[1] "min error is: 113393.552215232"
[1] "error rate calculated as 723948.185333408"
[1] "Considering k= 5 desamplingsize= 30 lambda 1"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "finished preprocessing 38 instances. Training network"
[1] "average error is: 761139.153235758"
[1] "max error is: 2783718.39635047"
[1] "min error is: 192028.655172436"
[1] "error rate calculated as 761139.153235758"
[1] "Considering k= 5 desamplingsize= 30 lambda 2"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "finished preprocessing 38 instances. Training network"
[1] "average error is: 737015.779872832"
[1] "max error is: 2907121.74977189"
[1] "min error is: 46671.7436427939"
[1] "error rate calculated as 737015.779872832"
[1] "Considering k= 5 desamplingsize= 30 lambda 4"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "finished preprocessing 38 instances. Training network"
[1] "average error is: 742176.463113288"
[1] "max error is: 2784223.95096874"
[1] "min error is: 58501.9555336479"
[1] "error rate calculated as 742176.463113288"
[1] "Considering k= 5 desamplingsize= 30 lambda 8"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "finished preprocessing 38 instances. Training network"
[1] "average error is: 757788.914257711"
[1] "max error is: 2989296.78787606"
[1] "min error is: 46972.0520010677"
[1] "error rate calculated as 757788.914257711"
[1] "Considering k= 5 desamplingsize= 30 lambda 16"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "finished preprocessing 38 instances. Training network"
[1] "average error is: 798587.776303292"
[1] "max error is: 3200920.24218086"
[1] "min error is: 15572.0138414527"
[1] "error rate calculated as 798587.776303292"
[1] "Considering k= 5 desamplingsize= 30 lambda 32"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "finished preprocessing 38 instances. Training network"
[1] "average error is: 817573.45507179"
[1] "max error is: 2931041.43525511"
[1] "min error is: 138308.20911815"
[1] "error rate calculated as 817573.45507179"
[1] "Considering k= 5 desamplingsize= 30 lambda 64"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "finished preprocessing 38 instances. Training network"
[1] "average error is: 788104.171063945"
[1] "max error is: 3021794.54893007"
[1] "min error is: 12638.1680164159"
[1] "error rate calculated as 788104.171063945"
[1] "Considering k= 5 desamplingsize= 30 lambda 128"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "finished preprocessing 38 instances. Training network"
[1] "average error is: 1416943.58838715"
[1] "max error is: 3475620.89663635"
[1] "min error is: 73733.1267355221"
[1] "error rate calculated as 1416943.58838715"
[1] "Considering k= 5 desamplingsize= 40 lambda 0"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "finished preprocessing 38 instances. Training network"
[1] "average error is: 752672.842650362"
[1] "max error is: 3005279.00542992"
[1] "min error is: 135995.24849934"
[1] "error rate calculated as 752672.842650362"
[1] "Considering k= 5 desamplingsize= 40 lambda 0.5"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "finished preprocessing 38 instances. Training network"
[1] "average error is: 681329.54099139"
[1] "max error is: 2622106.62164954"
[1] "min error is: 96079.3657083569"
[1] "error rate calculated as 681329.54099139"
[1] "Considering k= 5 desamplingsize= 40 lambda 1"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "finished preprocessing 38 instances. Training network"
[1] "average error is: 721168.806236016"
[1] "max error is: 2754071.31265971"
[1] "min error is: 144646.385216354"
[1] "error rate calculated as 721168.806236016"
[1] "Considering k= 5 desamplingsize= 40 lambda 2"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "finished preprocessing 38 instances. Training network"
[1] "average error is: 199000.245449646"
[1] "max error is: 499370.439803842"
[1] "min error is: 31283.4907998467"
[1] "error rate calculated as 199000.245449646"
[1] "Considering k= 5 desamplingsize= 40 lambda 4"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "finished preprocessing 38 instances. Training network"
[1] "average error is: 701138.141362503"
[1] "max error is: 2826971.72072632"
[1] "min error is: 71687.9972643152"
[1] "error rate calculated as 701138.141362503"
[1] "Considering k= 5 desamplingsize= 40 lambda 8"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "finished preprocessing 38 instances. Training network"
[1] "average error is: 171512.174561016"
[1] "max error is: 493719.335515782"
[1] "min error is: 80626.7316255667"
[1] "error rate calculated as 171512.174561016"
[1] "Considering k= 5 desamplingsize= 40 lambda 16"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "average error is: 175763.28463823"
[1] "max error is: 289631.741756447"
[1] "min error is: 32902.0850503063"
[1] "error rate calculated as 175763.28463823"
[1] "Considering k= 5 desamplingsize= 40 lambda 32"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "finished preprocessing 38 instances. Training network"
[1] "average error is: 744194.310842468"
[1] "max error is: 3101166.58985593"
[1] "min error is: 18322.0858590548"
[1] "error rate calculated as 744194.310842468"
[1] "Considering k= 5 desamplingsize= 40 lambda 64"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "finished preprocessing 38 instances. Training network"
[1] "average error is: 1374657.27373678"
[1] "max error is: 3251469.2050196"
[1] "min error is: 147436.662251736"
[1] "error rate calculated as 1374657.27373678"
[1] "Considering k= 5 desamplingsize= 40 lambda 128"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "finished preprocessing 38 instances. Training network"
[1] "average error is: 918422.530140131"
[1] "max error is: 3158980.8009504"
[1] "min error is: 262535.593643588"
[1] "error rate calculated as 918422.530140131"
[1] "Considering k= 5 desamplingsize= 50 lambda 0"
[1] "finished preprocessing 38 instances. Training network"
[1] "average error is: 740195.088577441"
[1] "max error is: 2930420.56025312"
[1] "min error is: 136888.12397705"
[1] "error rate calculated as 740195.088577441"
[1] "Considering k= 5 desamplingsize= 50 lambda 0.5"
[1] "preprocessed dataset from 15613 dimensions into  39 new dimensions"
[1] "finished preprocessing 38 instances. Training network"
[1] "average error is: 1269220.44916906"
[1] "max error is: 2924406.25043104"
[1] "min error is: 83517.2445385079"
[1] "error rate calculated as 1269220.44916906"
[1] "Considering k= 5 desamplingsize= 50 lambda 1"
[1] "preprocessed dataset from 15613 dimensions into  39 new dimensions"
[1] "finished preprocessing 38 instances. Training network"
[1] "average error is: 729364.814990645"
[1] "max error is: 2689567.33988295"
[1] "min error is: 69348.9690430782"
[1] "error rate calculated as 729364.814990645"
[1] "Considering k= 5 desamplingsize= 50 lambda 2"
[1] "preprocessed dataset from 15613 dimensions into  39 new dimensions"
[1] "finished preprocessing 38 instances. Training network"
[1] "average error is: 740427.962466163"
[1] "max error is: 3171315.63401032"
[1] "min error is: 36970.4954609956"
[1] "error rate calculated as 740427.962466163"
[1] "Considering k= 5 desamplingsize= 50 lambda 4"
[1] "preprocessed dataset from 15613 dimensions into  39 new dimensions"
[1] "average error is: 761777.389246905"
[1] "max error is: 2899709.36484488"
[1] "min error is: 208058.939414646"
[1] "error rate calculated as 761777.389246905"
[1] "Considering k= 5 desamplingsize= 50 lambda 8"
[1] "preprocessed dataset from 15613 dimensions into  39 new dimensions"
[1] "average error is: 161932.578573226"
[1] "max error is: 281338.049500344"
[1] "min error is: 77523.3941392418"
[1] "error rate calculated as 161932.578573226"
[1] "Considering k= 5 desamplingsize= 50 lambda 16"
[1] "preprocessed dataset from 15613 dimensions into  39 new dimensions"
[1] "finished preprocessing 38 instances. Training network"
[1] "average error is: 696356.984936385"
[1] "max error is: 2776266.55802893"
[1] "min error is: 54604.1630867861"
[1] "error rate calculated as 696356.984936385"
[1] "Considering k= 5 desamplingsize= 50 lambda 32"
[1] "preprocessed dataset from 15613 dimensions into  39 new dimensions"
[1] "finished preprocessing 38 instances. Training network"
[1] "average error is: 185505.687157752"
[1] "max error is: 299476.984355663"
[1] "min error is: 69691.2208339169"
[1] "error rate calculated as 185505.687157752"
[1] "Considering k= 5 desamplingsize= 50 lambda 64"
[1] "preprocessed dataset from 15613 dimensions into  39 new dimensions"
[1] "finished preprocessing 38 instances. Training network"
[1] "average error is: 233478.78438534"
[1] "max error is: 419063.938127942"
[1] "min error is: 68923.1105580348"
[1] "error rate calculated as 233478.78438534"
[1] "Considering k= 5 desamplingsize= 50 lambda 128"
[1] "preprocessed dataset from 15613 dimensions into  39 new dimensions"
[1] "average error is: 838529.548536762"
[1] "max error is: 3626942.31139659"
[1] "min error is: 37322.2374816195"
[1] "error rate calculated as 838529.548536762"
[1] "Considering k= 5 desamplingsize= 60 lambda 0"
[1] "preprocessed dataset from 15613 dimensions into  33 new dimensions"
[1] "average error is: 813166.714214656"
[1] "max error is: 2922257.16487508"
[1] "min error is: 115398.348342596"
[1] "error rate calculated as 813166.714214656"
[1] "Considering k= 5 desamplingsize= 60 lambda 0.5"
[1] "preprocessed dataset from 15613 dimensions into  33 new dimensions"
[1] "average error is: 699713.154352042"
[1] "max error is: 2783927.82136813"
[1] "min error is: 79974.2197464652"
[1] "error rate calculated as 699713.154352042"
[1] "Considering k= 15 desamplingsize= 20 lambda 4"
[1] "preprocessed dataset from 15613 dimensions into  93 new dimensions"
[1] "average error is: 1206026.95184562"
[1] "max error is: 2787504.72151888"
[1] "min error is: 60835.5672573771"
[1] "error rate calculated as 1206026.95184562"
[1] "Considering k= 15 desamplingsize= 20 lambda 8"
[1] "preprocessed dataset from 15613 dimensions into  93 new dimensions"
[1] "average error is: 803369.389625377"
[1] "max error is: 3116779.95682968"
[1] "min error is: 26549.5193665728"
[1] "error rate calculated as 803369.389625377"
[1] "Considering k= 15 desamplingsize= 20 lambda 16"
[1] "preprocessed dataset from 15613 dimensions into  93 new dimensions"
[1] "finished preprocessing 38 instances. Training network"
[1] "average error is: 1290957.76584074"
[1] "max error is: 2906335.79707644"
[1] "min error is: 196349.879688035"
[1] "error rate calculated as 1290957.76584074"
[1] "Considering k= 5 desamplingsize= 60 lambda 1"
[1] "preprocessed dataset from 15613 dimensions into  33 new dimensions"
[1] "average error is: 684526.425609079"
[1] "max error is: 2608865.13732858"
[1] "min error is: 32634.2349679506"
[1] "error rate calculated as 684526.425609079"
[1] "Considering k= 5 desamplingsize= 60 lambda 2"
[1] "preprocessed dataset from 15613 dimensions into  33 new dimensions"
[1] "average error is: 717776.847344347"
[1] "max error is: 2823116.3297613"
[1] "min error is: 86919.286488775"
[1] "error rate calculated as 717776.847344347"
[1] "Considering k= 5 desamplingsize= 60 lambda 4"
[1] "preprocessed dataset from 15613 dimensions into  33 new dimensions"
[1] "average error is: 703153.001218756"
[1] "max error is: 2669296.30409381"
[1] "min error is: 192367.299631792"
[1] "error rate calculated as 703153.001218756"
[1] "Considering k= 5 desamplingsize= 60 lambda 8"
[1] "preprocessed dataset from 15613 dimensions into  33 new dimensions"
[1] "average error is: 726714.377021663"
[1] "max error is: 3010099.45634419"
[1] "min error is: 95798.0943953794"
[1] "error rate calculated as 726714.377021663"
[1] "Considering k= 5 desamplingsize= 60 lambda 16"
[1] "preprocessed dataset from 15613 dimensions into  33 new dimensions"
[1] "average error is: 753310.058246499"
[1] "max error is: 2966718.14664193"
[1] "min error is: 58660.2582975906"
[1] "error rate calculated as 753310.058246499"
[1] "Considering k= 5 desamplingsize= 60 lambda 32"
[1] "preprocessed dataset from 15613 dimensions into  33 new dimensions"
[1] "average error is: 1369460.39410293"
[1] "max error is: 3328229.30682541"
[1] "min error is: 92959.3604112758"
[1] "error rate calculated as 1369460.39410293"
[1] "Considering k= 5 desamplingsize= 60 lambda 64"
[1] "preprocessed dataset from 15613 dimensions into  33 new dimensions"
[1] "average error is: 847788.009344673"
[1] "max error is: 3455009.12217398"
[1] "min error is: 93850.9250794582"
[1] "error rate calculated as 847788.009344673"
[1] "Considering k= 5 desamplingsize= 60 lambda 128"
[1] "preprocessed dataset from 15613 dimensions into  33 new dimensions"
[1] "finished preprocessing 38 instances. Training network"
[1] "average error is: 850044.384830145"
[1] "max error is: 3120193.91956178"
[1] "min error is: 6378.32090248005"
[1] "error rate calculated as 850044.384830145"
[1] "Considering k= 10 desamplingsize= 20 lambda 0"
[1] "preprocessed dataset from 15613 dimensions into  93 new dimensions"
[1] "average error is: 730105.767661961"
[1] "max error is: 2570065.71681852"
[1] "min error is: 113117.646710072"
[1] "error rate calculated as 730105.767661961"
[1] "Considering k= 10 desamplingsize= 20 lambda 0.5"
[1] "preprocessed dataset from 15613 dimensions into  93 new dimensions"
[1] "average error is: 863743.789715949"
[1] "max error is: 2866489.55873318"
[1] "min error is: 124460.272641784"
[1] "error rate calculated as 863743.789715949"
[1] "Considering k= 10 desamplingsize= 20 lambda 1"
[1] "preprocessed dataset from 15613 dimensions into  93 new dimensions"
[1] "finished preprocessing 38 instances. Training network"
[1] "average error is: 736325.963904073"
[1] "max error is: 2705336.16179834"
[1] "min error is: 102852.410799852"
[1] "error rate calculated as 736325.963904073"
[1] "Considering k= 10 desamplingsize= 20 lambda 2"
[1] "preprocessed dataset from 15613 dimensions into  93 new dimensions"
[1] "average error is: 694632.532866662"
[1] "max error is: 2886718.84317824"
[1] "min error is: 52384.3677949128"
[1] "error rate calculated as 694632.532866662"
[1] "Considering k= 10 desamplingsize= 20 lambda 4"
[1] "preprocessed dataset from 15613 dimensions into  93 new dimensions"
[1] "average error is: 1294421.17019738"
[1] "max error is: 3136801.45357868"
[1] "min error is: 40422.3865012717"
[1] "error rate calculated as 1294421.17019738"
[1] "Considering k= 10 desamplingsize= 20 lambda 8"
[1] "preprocessed dataset from 15613 dimensions into  93 new dimensions"
[1] "average error is: 794344.134844959"
[1] "max error is: 3150982.30548374"
[1] "min error is: 129103.996691435"
[1] "error rate calculated as 794344.134844959"
[1] "Considering k= 10 desamplingsize= 20 lambda 16"
[1] "preprocessed dataset from 15613 dimensions into  93 new dimensions"
[1] "average error is: 750348.398992371"
[1] "max error is: 2813567.9892354"
[1] "min error is: 40311.5978230075"
[1] "error rate calculated as 750348.398992371"
[1] "Considering k= 10 desamplingsize= 20 lambda 32"
[1] "preprocessed dataset from 15613 dimensions into  93 new dimensions"
[1] "average error is: 743129.587831027"
[1] "max error is: 3040048.8985497"
[1] "min error is: 20388.6606716671"
[1] "error rate calculated as 743129.587831027"
[1] "Considering k= 10 desamplingsize= 20 lambda 64"
[1] "preprocessed dataset from 15613 dimensions into  93 new dimensions"
[1] "average error is: 797005.358632089"
[1] "max error is: 3384685.55839322"
[1] "min error is: 5979.07207778347"
[1] "error rate calculated as 797005.358632089"
[1] "Considering k= 10 desamplingsize= 20 lambda 128"
[1] "preprocessed dataset from 15613 dimensions into  93 new dimensions"
[1] "average error is: 829286.863014256"
[1] "max error is: 3163934.38944952"
[1] "min error is: 97978.3970983686"
[1] "error rate calculated as 829286.863014256"
[1] "Considering k= 10 desamplingsize= 30 lambda 0"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "average error is: 1252651.59889142"
[1] "max error is: 2902717.73507971"
[1] "min error is: 75209.0696851919"
[1] "error rate calculated as 1252651.59889142"
[1] "Considering k= 10 desamplingsize= 30 lambda 0.5"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "average error is: 658844.031699222"
[1] "max error is: 2649601.2482262"
[1] "min error is: 47115.5159199758"
[1] "error rate calculated as 658844.031699222"
[1] "Considering k= 10 desamplingsize= 30 lambda 1"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "average error is: 1192617.85128383"
[1] "max error is: 2773405.77563349"
[1] "min error is: 163520.46586178"
[1] "error rate calculated as 1192617.85128383"
[1] "Considering k= 10 desamplingsize= 30 lambda 2"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "average error is: 719357.464322458"
[1] "max error is: 2627057.62786641"
[1] "min error is: 172085.967415266"
[1] "error rate calculated as 719357.464322458"
[1] "Considering k= 10 desamplingsize= 30 lambda 4"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "average error is: 783311.653345832"
[1] "max error is: 3015738.3810478"
[1] "min error is: 186223.164982024"
[1] "error rate calculated as 783311.653345832"
[1] "Considering k= 10 desamplingsize= 30 lambda 8"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "average error is: 793176.398493365"
[1] "max error is: 3079594.99066459"
[1] "min error is: 62928.5600731091"
[1] "error rate calculated as 793176.398493365"
[1] "Considering k= 10 desamplingsize= 30 lambda 16"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "average error is: 761502.66819481"
[1] "max error is: 3194014.61566576"
[1] "min error is: 14246.1089270561"
[1] "error rate calculated as 761502.66819481"
[1] "Considering k= 10 desamplingsize= 30 lambda 32"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "average error is: 185049.649877237"
[1] "max error is: 465906.427345217"
[1] "min error is: 32161.5523873281"
[1] "error rate calculated as 185049.649877237"
[1] "Considering k= 10 desamplingsize= 30 lambda 64"
[1] "preprocessed dataset from 15613 dimensions into  63 new dimensions"
[1] "average error is: 1421589.34310533"
[1] "max error is: 3445278.55983322"
[1] "min error is: 105188.990566923"
[1] "error rate calculated as 1421589.34310533"
[1] "Considering k= 10 desamplingsize= 30 lambda 128"
[1] "average error is: 882367.852934442"
[1] "max error is: 3243701.01539784"
[1] "min error is: 1892.98432311209"
[1] "error rate calculated as 882367.852934442"
[1] "Considering k= 10 desamplingsize= 40 lambda 0"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "average error is: 450874.168193155"
[1] "max error is: 733679.35326175"
[1] "min error is: 123826.653718233"
[1] "error rate calculated as 450874.168193155"
[1] "Considering k= 10 desamplingsize= 40 lambda 0.5"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "average error is: 723510.498336607"
[1] "max error is: 3157007.84452501"
[1] "min error is: 60264.782026035"
[1] "error rate calculated as 723510.498336607"
[1] "Considering k= 10 desamplingsize= 40 lambda 1"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "average error is: 796297.593291561"
[1] "max error is: 3200889.58685568"
[1] "min error is: 138300.812365308"
[1] "error rate calculated as 796297.593291561"
[1] "Considering k= 10 desamplingsize= 40 lambda 2"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "average error is: 786393.769144376"
[1] "max error is: 3072489.06557617"
[1] "min error is: 40595.1558637361"
[1] "error rate calculated as 786393.769144376"
[1] "Considering k= 10 desamplingsize= 40 lambda 4"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "average error is: 702359.704437908"
[1] "max error is: 2832442.60423049"
[1] "min error is: 65713.7646753576"
[1] "error rate calculated as 702359.704437908"
[1] "Considering k= 10 desamplingsize= 40 lambda 8"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "average error is: 666390.238831387"
[1] "max error is: 2912991.70394229"
[1] "min error is: 18168.8708402077"
[1] "error rate calculated as 666390.238831387"
[1] "Considering k= 10 desamplingsize= 40 lambda 16"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "average error is: 720985.120729691"
[1] "max error is: 2871590.32452403"
[1] "min error is: 133013.805384262"
[1] "error rate calculated as 720985.120729691"
[1] "Considering k= 10 desamplingsize= 40 lambda 32"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "average error is: 818754.825438956"
[1] "max error is: 3183553.71987649"
[1] "min error is: 95832.5832806921"
[1] "error rate calculated as 818754.825438956"
[1] "Considering k= 10 desamplingsize= 40 lambda 64"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "average error is: 733616.606819837"
[1] "max error is: 2993299.99311301"
[1] "min error is: 35857.2730585246"
[1] "error rate calculated as 733616.606819837"
[1] "Considering k= 10 desamplingsize= 40 lambda 128"
[1] "preprocessed dataset from 15613 dimensions into  48 new dimensions"
[1] "average error is: 863477.276768381"
[1] "max error is: 3187516.35663566"
[1] "min error is: 80470.8969864683"
[1] "error rate calculated as 863477.276768381"
[1] "Considering k= 10 desamplingsize= 50 lambda 0"
[1] "preprocessed dataset from 15613 dimensions into  39 new dimensions"
[1] "average error is: 729524.696242778"
[1] "max error is: 2978290.10098367"
[1] "min error is: 73168.2421096733"
[1] "error rate calculated as 729524.696242778"
[1] "Considering k= 10 desamplingsize= 50 lambda 0.5"
[1] "preprocessed dataset from 15613 dimensions into  39 new dimensions"
[1] "average error is: 750064.55958495"
[1] "max error is: 2980236.22042749"
[1] "min error is: 99959.2072038784"
[1] "error rate calculated as 750064.55958495"
[1] "Considering k= 10 desamplingsize= 50 lambda 1"
[1] "preprocessed dataset from 15613 dimensions into  39 new dimensions"
[1] "average error is: 758929.650589325"
[1] "max error is: 2717336.57230535"
[1] "min error is: 86055.6379619558"
[1] "error rate calculated as 758929.650589325"
[1] "Considering k= 10 desamplingsize= 50 lambda 2"
[1] "preprocessed dataset from 15613 dimensions into  39 new dimensions"
[1] "average error is: 678622.880198117"
[1] "max error is: 2704768.07972309"
[1] "min error is: 90867.1762124648"
[1] "error rate calculated as 678622.880198117"
[1] "Considering k= 10 desamplingsize= 50 lambda 4"
[1] "preprocessed dataset from 15613 dimensions into  39 new dimensions"
[1] "average error is: 1221478.48814775"
[1] "max error is: 2795018.92810623"
[1] "min error is: 55265.7715017427"
[1] "error rate calculated as 1221478.48814775"
[1] "Considering k= 10 desamplingsize= 50 lambda 8"
[1] "preprocessed dataset from 15613 dimensions into  39 new dimensions"
[1] "average error is: 714973.89681987"
[1] "max error is: 2935412.7826034"
[1] "min error is: 60481.9222703478"
[1] "error rate calculated as 714973.89681987"
[1] "Considering k= 10 desamplingsize= 50 lambda 16"
[1] "preprocessed dataset from 15613 dimensions into  39 new dimensions"
[1] "average error is: 856378.594034321"
[1] "max error is: 3199221.41832696"
[1] "min error is: 26456.1699147919"
[1] "error rate calculated as 856378.594034321"
[1] "Considering k= 10 desamplingsize= 50 lambda 32"
[1] "preprocessed dataset from 15613 dimensions into  39 new dimensions"
[1] "average error is: 819485.913353072"
[1] "max error is: 3628235.66880476"
[1] "min error is: 46284.2458683102"
[1] "error rate calculated as 819485.913353072"
[1] "Considering k= 10 desamplingsize= 50 lambda 64"
[1] "preprocessed dataset from 15613 dimensions into  39 new dimensions"
[1] "average error is: 193667.046036611"
[1] "max error is: 411043.076313004"
[1] "min error is: 34766.2771251888"
[1] "error rate calculated as 193667.046036611"
[1] "Considering k= 10 desamplingsize= 50 lambda 128"
[1] "preprocessed dataset from 15613 dimensions into  39 new dimensions"
[1] "average error is: 783498.433463816"
[1] "max error is: 3002586.65796111"
[1] "min error is: 14958.2616885263"
[1] "error rate calculated as 783498.433463816"
[1] "Considering k= 10 desamplingsize= 60 lambda 0"
[1] "preprocessed dataset from 15613 dimensions into  33 new dimensions"
[1] "average error is: 955468.868646034"
[1] "max error is: 2857764.29474129"
[1] "min error is: 153575.676958532"
[1] "error rate calculated as 955468.868646034"
[1] "Considering k= 10 desamplingsize= 60 lambda 0.5"
[1] "preprocessed dataset from 15613 dimensions into  33 new dimensions"
[1] "average error is: 1259596.41635106"
[1] "max error is: 2953336.09337116"
[1] "min error is: 44313.2493778094"
[1] "error rate calculated as 1259596.41635106"
[1] "Considering k= 10 desamplingsize= 60 lambda 1"
[1] "preprocessed dataset from 15613 dimensions into  33 new dimensions"
[1] "average error is: 173153.676141924"
[1] "max error is: 232443.660474533"
[1] "min error is: 129356.079052299"
[1] "error rate calculated as 173153.676141924"
[1] "Considering k= 10 desamplingsize= 60 lambda 2"
[1] "preprocessed dataset from 15613 dimensions into  33 new dimensions"
[1] "average error is: 727763.548988452"
[1] "max error is: 2879441.67204181"
[1] "min error is: 127777.494006063"
[1] "error rate calculated as 727763.548988452"
[1] "Considering k= 10 desamplingsize= 60 lambda 4"
[1] "preprocessed dataset from 15613 dimensions into  33 new dimensions"
[1] "average error is: 675088.992973882"
[1] "max error is: 2665091.3976278"
[1] "min error is: 107411.042518455"
[1] "error rate calculated as 675088.992973882"
[1] "Considering k= 10 desamplingsize= 60 lambda 8"
[1] "preprocessed dataset from 15613 dimensions into  33 new dimensions"
[1] "average error is: 1322814.31964974"
[1] "max error is: 3157815.74378247"
[1] "min error is: 24729.3248389045"
[1] "error rate calculated as 1322814.31964974"
[1] "Considering k= 10 desamplingsize= 60 lambda 16"
[1] "preprocessed dataset from 15613 dimensions into  33 new dimensions"
[1] "average error is: 1263200.4660027"
[1] "max error is: 3200548.58374486"
[1] "min error is: 9425.51941304366"
[1] "error rate calculated as 1263200.4660027"
[1] "Considering k= 10 desamplingsize= 60 lambda 32"
[1] "preprocessed dataset from 15613 dimensions into  33 new dimensions"
[1] "average error is: 838034.950387567"
[1] "max error is: 3462934.05771967"
[1] "min error is: 34159.878293747"
[1] "error rate calculated as 838034.950387567"
[1] "Considering k= 10 desamplingsize= 60 lambda 64"
[1] "preprocessed dataset from 15613 dimensions into  33 new dimensions"
[1] "finished preprocessing 38 instances. Training network"
[1] "average error is: 785474.249494602"
[1] "max error is: 3227533.24989291"
[1] "min error is: 15030.8788568168"
[1] "error rate calculated as 785474.249494602"
[1] "Considering k= 10 desamplingsize= 60 lambda 128"
[1] "preprocessed dataset from 15613 dimensions into  33 new dimensions"
[1] "average error is: 788563.859688403"
[1] "max error is: 3158053.83300026"
[1] "min error is: 123100.282832992"
[1] "error rate calculated as 788563.859688403"
[1] "Considering k= 15 desamplingsize= 20 lambda 0"
[1] "preprocessed dataset from 15613 dimensions into  93 new dimensions"
[1] "average error is: 737464.053739207"
[1] "max error is: 2958709.01014297"
[1] "min error is: 67891.902946903"
[1] "error rate calculated as 737464.053739207"
[1] "Considering k= 15 desamplingsize= 20 lambda 0.5"
[1] "preprocessed dataset from 15613 dimensions into  93 new dimensions"
[1] "average error is: 1353828.25570509"
[1] "max error is: 2820797.93425417"
[1] "min error is: 80342.5087061614"
[1] "error rate calculated as 1353828.25570509"
[1] "Considering k= 15 desamplingsize= 20 lambda 1"
[1] "preprocessed dataset from 15613 dimensions into  93 new dimensions"
[1] "average error is: 732678.191997122"
[1] "max error is: 2704784.94736467"
[1] "min error is: 43468.6517656548"
[1] "error rate calculated as 732678.191997122"
[1] "Considering k= 15 desamplingsize= 20 lambda 2"
[1] "preprocessed dataset from 15613 dimensions into  93 new dimensions"

